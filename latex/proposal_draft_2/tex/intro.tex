This project is sponsored by the UBC Sailbot team, with the goal of overcoming a significant challenge to autonomous robotic vessels on open water: floating hazards. Debris in the water is difficult to detect, and attempts made to cross the Atlantic ocean with such an autonomous boat have often been sunk by aquatic hazards.

\subsection{\label{sec:intro:key-issues}Key Issues}
The greatest challenge is to reliably produce an accurate model of the boat's surroundings. The first challenge is to test the system with limited ability to test on the water.  Waves will be particularly difficult to test with.  Finally, the solution must be able to examine its surrounding under varied light conditions, and with minimal processing power.

A robotic vision system requires extensive calibration and offline analysis of the signals it produces. Since testing on the water requires considerable time, it is infeasible to adequately examine the capabilities of the vision system without an on-shore testing environment that closely matches conditions. Such an environment should be able to simulate bright and dark lighting conditions, sections of view that are blocked by other equipment, fog and rain, as well as the motion of the boat.

Also, the processing power of the vision system is physically constrained by the capabilities of Raspberry Pi (or similar) hardware, and further constrained by the need to minimize the energy use of the hardware while examining the environment in realtime. To accomplish this, information provided by sensors may need to be cleverly downsampled, and processing algorithms should be selected based on performance while potentially compromising accuracy for speed.

\subsection{\label{sec:intro:existing-solutions}Existing Solutions}

The Sailbot team has an existing IR navigation system - we need to assess its strengths and weaknesses when we meet with them, and determine the areas where improvements are needed.  We expect to need another system to either replace or supplement IR detection.  Environmental conditions such as fog, rain, and waves may make IR detection unreliable, and its range may be limited compared to other systems.  More detail will become available as we discuss this with our project sponsor.

\subsection{\label{sec:intro:technical-background}Technical Background}
Potential detection systems:
\begin{itemize}

\item Lidar (visible or IR): 
low cost and power consumption, good resolution

Easily obscured in adverse conditions - could result in missing objects

\item Cameras: 
Cheapest, existing software may be usable

Processing intensive, only provides 2D images, lens must remain clean.  Difficult to distinguish obstacles from water

\item Radar:
Long range, high-quality preexisting units available

May be unable to detect nearby objects.  Size and power consumption concerns

\item Sonar:
Relatively long range, reliable detection

Housing may be difficult, may be more difficult to integrate into existing boat

\item Passive acoustic:
Possible supplement to other systems - detect ships.  Low cost, very low power - emergency backup detection?

Can't detect many obstacles.  Doesn't provide directional information.
\end{itemize}

\subsection{\label{sec:intro:commercial}State of the Art}
Our budget is initially limited to \$1500, with more funding potentially available for promising solutions. This ceiling rules out most commercial products, however it is useful to examine their features for comparison against our requirements.

The Autonomous Maritime Navigation Project uses a combination of radar, lidar, and optical cameras for autonomous small-boat navigation.

A high-performance LIDAR system developed by Velodyne (the Velodyne Lidar Puck VLP-16 \cite{velodyne-vlp16}) selling at a minimum cost of \$8000 is the standard of 3-dimensional autonomous vision. This system offers a viewing area of 360$\degree$ horizontal, 30$\degree$ vertical, with 300 000 measurement points delivered every second, effectively forming a 3D point mesh within the viewport. Velodyne's more expensive and more capable products are used by Google's autonomous vehicles.

\subsection{\label{sec:intro:alternatives}Alternative Strategies}
We will likely use some combination of the systems discussed under Technical Background.  Which systems we use will depend on the sponsor's needs and the technical problems we face.

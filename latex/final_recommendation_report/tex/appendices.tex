\appendix
% Show appendix character in front of subsection number.
\renewcommand{\thesubsection}{\Alph{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection.\arabic{subsubsection}}
\subsection{\label{app:AppendixA}Devision of Labour}
Our work with the Sailbot team primarily involved collaborating with:

\begin{itemize}
 \item Paul Cernek, head of Sailbot's Obstacle Avoidance subteam
 \item Josh Baker, member of Sailbot's Controls and OA subteams
 \item Josh Andrews, head of Sailbot's Software team
 \item Derek Lun, member of Sailbot's OA subteam
 \item Arek Sredski, head of Sailbot's Control team
 \item Krisoffer Vik Hansen, Sailbot team Captain
\end{itemize}

While many areas of the work done on the OA system were a result of collaboration between many of the members on this project, certain aspects are more associated with some subgroups than others. Hardware development was primarily taken care of by the Engineering Physics group members, while the working obstacle detection software (the bounding boxes) was developed primarily by Sailbot members (in particular Arek, Paul, and Josh Baker). The code to establish basic Lepton functionality, video encoding, and wireless communication was jointly developed, as was the programming and integration of the IMU. Overall software architecture and pipelining was a joint effort, although this architecture is largely skeletal at the time of writing this report pending the purchase of a Quark2 camera. All testing excursions were equally attended by Eng Phys members and Sailbot members, with planning and logistics credit going to Paul.

Extra thanks are extended to Jon Mikkelsen, Sailbot's Faculty Sponsor for offering advice, insight, and test facilities throughout this project.

\clearpage
\newpage
\subsection{\label{app:AppendixB}Obstacle detection} 

\begin{figure}[h]
\includegraphics[width=70mm,natwidth=505,natheight=394]{"./image/directional-emitters"}
\caption[Minimum distance to detected obstacle.]{\label{fig:emitter-angle}Minimum detection distance for a directional emitter.}
\end{figure}

\subsubsection{\label{app:minimum-detection-distance}Minimum detection distance}
Constraints on the viewing area appear with any method of detection, whether radar, lidar, on infrared. For directional emitters, the minimum detection range is given by trigonometry and depends only on the vertical beam width and the mounting angle of the device. $d = h/\text{tan}(\eta)$, where $\eta=\pi/2-(\theta/2+\phi)$ given by $\theta$, the vertical beam spread, and $\phi$, the emitter mount angle. Figure \ref{fig:emitter-angle} details the trigonometric analysis.

\subsubsection{\label{app:obstacle-frequency}Frequency of floating obstacles}
Given the vast size of the Atlantic ocean, floating obstacles are rare. Nevertheless, it is instructive to provide a reasonable guess of the space between obstacles of different types.

\begin{table}[h]
\caption{\label{tab:obstacles}Obstacles and risk}
\begin{tabular}{c|c|c|c}

Obstacle & Location & Inverse Frequency & Damage\\[0.6cm]
\hline

Shipping vessels & Entire route & 4 days & Severe \\
Icebergs & Entire route & 400 days & Severe \\
Logs & Entire route, drawn to gyres & 40 days & Moderate \\

\end{tabular}
\end{table}

From \cite{jallal__how-many-ships}, we can say that there are about 50000 container ships in the world at any given moment. These travel at about 25 knots (50 km/h) \cite{maersk__triple-e-class}, making the 3000km Atlantic crossing in about 20 days. The turnaround time (the length of time spent in port is about 1 day \cite{port-technology__global-turnaround-times}, which will be neglected here).

Let's assume 20\% of the world's shipping occurs somewhere in the north atlantic, near our route. The Microtransat organisers estimate that it will take our boat two to three months to complete the crossing, so that a given ship can be assumed to cross our route five times during our trip. Eyeballing, the area of ocean of interest, bounded by the most northern and southern routes the Sailbot is likely to take, is 1/10 of the full 100 Mkm size of the Atlantic \cite{worldatlas__atlantic-ocean}.

So, we have $\frac{10000000}{0.2*50000*5}=200$. This is the average area of ocean, in km$^2$, containing one shipping vessel.

To convert to a frequency, we can assume that ships are stationary and expand the width of the Sailbot to a typical length of a ship, say 100m. Traveling at 20km/h, the Sailbot then sweeps an area of 2km$^2$/h, leading to one ship encounter per 100 hours or roughly 4 days.

Now, during peak season, there are about 1000 icebergs in the North Atlantic \cite{natgeo__iceberg-frequency}. This is about 50 times less than the number of ships, leading to an inverse area density of one per 10000 km$^2$, and a frequency of 1 encounter per 400 days


\clearpage
\newpage
\subsection{\label{app:software-testing-methodology}Software Testing Methodology}
This appendix outlines a particular form of test driven development, inspired by Peter Provost \cite{provost-tdd} and James O. Coplien \cite{coplien-tdd-waste}.

The correct functioning of software is checked at every stage of development, using three levels, two of which are automated. The three levels are unit tests and functional tests, performed by testing software; and user tests, performed manually.

Software code not depending on hardware interaction is examined through unit tests, which verify that functions produce the correct output under all anticipated conditions. These tests are written before or simultaneously with the code to be tested.

The emergent, holistic functionality of the software (including user interface elements are outputs) can be tested using functional tests that provide simulated realistic input, possibly simulating hardware components, and examine the output.

The final test level is user tests, which include testing on the actual vessel in real and simulated environments, as well as any other manual testing.

These test levels are not performed in sequence; all testing levels should interact with the development process, and be re-evaluated whenever a notable change is made. Figure \ref{fig:software-testing} shows the connection of testing and development.

\begin{figure}[h]
\includegraphics[width=100mm,natwidth=494,natheight=299]{"./image/software-testing"}
\caption[Software development cycle]{\label{fig:software-testing}Development cycle. Tests are written before or simultaneously with production code, and both automated and manual testing is run intermittently during development.}
\end{figure}


\subsubsection{\label{sec:discussion:theory:detectionoverview}Obstacle Detection Overview}
While sailors have used navigation aides for many years, only recently has there been an interest in developing autonomous vehicles that could navigate themselves around the ocean for extended periods of time. While there is a wealth of information available on object detection for autonomous surface vehicles \cite{detection-offroad} \cite{optical-flow-detection} \cite{unmanned-ground-vehicles}, many of these techniques involve laser rangefinding or stereo vision in static, sterile environments. None of these techniques are easily applicable to an ocean environment, where the platform and environment are never static, waves and fog mean a constant air/water boundary has to be considered, salt poses a corrosive threat and marine life may grow on or distort the imaging medium. 

Autonomous underwater vehicles use forward looking sonar but the moving air/water medium for a boat on the surface makes sonar difficult to use when not completely submersed. While profiling sonar has been used in a research capacity on a surface boat\cite{ASV-sonar} the profiling system was only effective when tested on a small lake with a slow-moving boat, for objects at a distance of <30m. This case is a far cry from the conditions that the Sailbot will experience, and furthermore cost considerations rule out sonar obstacle detection systems for us.


The most applicable research we found to our work with the Lepton infrared camera was done at the Old Dominion University in Viriginia, by their Computational Intelligence and Machine Vision Labratory. The ODU lab had developed an algorithm to count boats passing into a harbour by use of an infrared camera, primarily through the use of adaptive thresholding and training a machine learning algorithm on a large database of boat images; however, their work could be fooled on even slightly wavey water, as it was designed with harbour conditions in mind. Watching the sample video on their site shows the algorithm misidentifying water as an obstacle when there are even minor waves.\cite{ODU-boat-IR-detection} Despite this, ODU's work shows that IR imaging holds promise in marine obstacle detection, and much of our work follows their model.

\subsubsection{\label{sec:discussion:theory:detectionsoftware}Software}
Acquiring a usable image is only the first step in object detection. In order to train the software to see the objects in the frame, we apply many of the basic algorithms that the human brain uses to identify and partition objects. Our eyes are developed to look for sharp lines and movement against a background; much of the work in machine vision focuses on image segmentation and object tracking, similarly. 

In the ideal detection case, we would see a large boat on still water, with a clear sky. In this ideal image, the only sharp lines are those which define the boat and the horizon, at which point linefinding is easy and detection is trivial. However, the imaging conditions that Sailbot will experience are sure to be far from ideal; waves create varying angles of incidence, meaning a varying IR intensity across uniform-temperature water, the boats may be small and far away, and the Sailbot won't ever be still. This means that image smoothing must occur; filters must be in place to help segment the image and discard noise. While basic smoothing can take place as simple blurring (see Figure \ref{fig:blurring:sub1}, an example from the O'Rielly OpenCV textbook on computer vision), simple techniques such as mean or median blurring (where the pixel value is set to the mean/median of those around it) is a highly lossy technique. Guassian smoothing (or bilateral smoothing, which is gaussian with a bias towards similarly-coloured pixels) is much better at preserving edges while smoothing low frequency noise (see Figure \ref{fig:blurring:sub2}).

\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
 \centering
 \includegraphics[width=0.95\textwidth]{"./image/median_blurring"}
 \caption{Blurring by taking the median of the surrounding pixels.}
 \label{fig:blurring:sub1}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
 \centering
 \includegraphics[width=0.95\textwidth]{"./image/bilateral_smoothing"}
 \caption{Bilateral smoothing; applying a weighted guassian smoothing.}
 \label{fig:blurring:sub2}
\end{subfigure}
\caption{Two blurring techniques to cut down noise}
\label{fig:blurring}
\end{figure}

The FLIR Lepton camera we're using for this project is a very low resolution camera- only 80x60 in a 50 degree field of view- so smoothing is not really needed; each pixel covers several square feet of most objects it's looking at, so the images look like they've been through a heavy mean filtering process already (Figure \ref{fig:buoy_ex}. However, should the Sailbot upgrade to a higher resolution camera (as is being currently considered) then smoothing algorithms while play a more important role in our postprocessing. 

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{"./image/buoy_example"}
\caption{Buoy at 50 meters, no smoothing or processing}
\label{fig:buoy_ex}
\end{figure}

After reducing noise, increasing contrast and thresholding help to segment the image. In scenes such as infrared pictures taken during rain or through heavy fog, much of the IR light will be scattered resulting in washed-out pictures (see Figure \ref{fig:washedOut} taken at midafternoon on a foggy day of testing in Ucluelet). When the obstacles are close, the contrast in the background is not a problem as the object sticks out quite obviously. However, far-off objects will have less contrast, where applying a histogram equilization helps to increase the range of pixels used. Figure \ref{fig:hist_equil} illustrates the effect that the histogram equilization can have; by mapping the histogram of pixel intensity values to a cumulative gaussian distribution, the full range of pixels can be utilized. In scenes with little or no information (such as that in Figure \ref{fig:washedOut}) gain no net benefit from increasing contrast.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{"./image/washed-out_example"}
\caption{Boat at 100m to 150m through fog}
\label{fig:washedOut}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
 \centering
 \includegraphics[width=0.95\textwidth]{"./image/hist_equil_1"}
 \caption{Low contrast example.}
 \label{fig:hist_equil:sub1}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
 \centering
 \includegraphics[width=0.95\textwidth]{"./image/hist_equil_2"}
 \caption{Post-processing.}
 \label{fig:hist_equil:sub2}
\end{subfigure}
\caption{Increasing contrast with histogram equilization.}
\label{fig:hist_equil}
\end{figure}

The next step in most traditional object detection algorithms is applying a thresholding technique; blocking off all pixels less than a certain intensity value is an easy way to prioritize close, large, easy-to-identify objects. Particularly with infrared imaging, the pixel intensity given off by an object is proportional to its heat; in the ocean, boats are drastically warmer than the ocean surrounding them. In addition, a ceiling threshold helps to eliminate the sun as a potential obstacle, at the recorded intensity of the sun is orders of magnitude higher than those of most any terrestrial objects. Rather than apply a static threshold, as the recorded pixel values can vary by large amounts depending on the time of day, position of the sun, cloud cover, and fog, an adaptive threshold is much more useful. Adaptive thresholds are "smarter" thresholds, given that they take into account the overall pixel intensities in the image and apply a differing threshold to each part of the image based on its surroundings. Adaptive thresholds excel at accounting for lighting differences, but in our application they can help account for sun position and waves. Figure \ref{fig:thresh_comp} illustrates the benefit of adaptive thresholds over traditional binary thresholds.

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{"./image/threshold_comparisons"}
\caption{Simple vs Adaptive Thresholding.}
\label{fig:thresh_comp}
\end{figure}

Finally, after as much extraneous information has been removed as possible, edge detection algorithms can be applied to find areas of complex geometry in the image. The most commonplace edge detection algorithm is Canny edge detection, which maps the first and second derivatives in both horizontal and vertical directions over the image before looking for local maxima and minima; by pairing these extrema with a gradient analysis and applying a threshold to filter for high rates of change, the Canny algorithm is very effective at finding edges. In the Sailbot case, we can use Canny edge detection on our filtered images to identify areas with many edges. 
\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{"./image/canny"}
\caption{Canny edge detection.}
\label{fig:canny}
\end{figure}

High concentrations of edges combined with lines at sharp angles to the horizon have a high likelihood to be an obstacle, while very rarely being triggered by ocean waves or other noise. Since obtacles prove to be persistent where noise doesn't trip the algorithm often enough, weighting an obstacle's likelihood of existence by it's frequency of appearance is a strong method to filter out false positives while limiting the chance of false negatives.


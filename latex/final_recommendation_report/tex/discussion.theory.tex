
\subsubsection{\label{sec:discussion:theory:detectionoverview}Obstacle Detection Overview}
While sailors have used navigation aides for many years, only recently has there been an interest in developing autonomous vehicles that could navigate themselves around the ocean for extended periods of time. While there is a wealth of information available on object detection for autonomous surface vehicles \cite{detection-offroad} \cite{optical-flow-detection} \cite{unmanned-ground-vehicles}, many of these techniques involve laser rangefinding or stereo vision in static, sterile environments. None of these techniques are easily applicable to an ocean environment, where the platform and environment are never static, waves and fog mean a constant air/water boundary has to be considered, salt posses a corrosive threat and marine life may grow on or distort the imaging medium. 

Autonomous underwater vehicles use forward looking sonar but the moving air/water medium for a boat on the surface makes sonar difficult to use when not completely submersed. While profiling sonar has been used in a research capacity on a surface boat\cite{ASV-sonar} the profiling system was only effective when tested on a small lake with a slow-moving boat, for objects at a distance of <30m. This case is a far cry from the conditions that the Sailbot will experience, and furthermore cost considerations rule out sonar obstacle detection systems for us.


The most applicable research we found to our work with the Lepton infrared camera was done at the Old Dominion University in Viriginia, by their Computational Intelligence and Machine Vision Labratory. The ODU lab had developed an algorithm to count boats passing into a harbour by use of an infrared camera, primarily through the use of adaptive thresholding and training a machine learning algorithm on a large database of boat images; however, their work could be fooled on even slightly wavey water, as it was designed with harbour conditions in mind. Watching the sample video on their site shows the algorithm misidentifying water as an obstacle when there are even minor waves.\cite{ODU-boat-IR-detection} Despite this, ODU's work shows that IR imaging holds promise in marine obstacle detection, and much of our work follows their model.

\subsubsection{\label{sec:discussion:theory:detectionsoftware}Software}
Acquiring a usable image is only the first step in object detection. In order to train the software to see the objects in the frame, we apply many of the basic algorithms that the human brain uses to identify and partition objects. Our eyes are developed to look for sharp lines and movement against a background; much of the work in machine vision focuses on image segmentation and object tracking, similarly. 

In the ideal detection case, we would see a large boat on still water, with a clear sky. In this ideal image, the only sharp lines are those which define the boat and the horizon, at which point linefinding is easy and detection is trivial. However, the imaging conditions that Sailbot will experience are sure to be far from ideal; waves create varying angles of incidence, meaning a varying IR intensity across uniform-temperature water, the boats may be small and far away, and the Sailbot won't ever be still. This means that image smoothing must occur; filters must be in place to help segment the image and discard noise. While basic smoothing can take place as simple blurring (see Figure \ref{fig:blurring:sub1}, an example from the O'Rielly OpenCV textbook on computer vision), simple techniques such as mean or median blurring (where the pixel value is set to the mean/median of those around it) is a highly lossy technique. Guassian smoothing (or bilateral smoothing, which is guassian with a bias towards similarly-coloured pixels) is much better at preserving edges while smoothing low frequency noise (see Figure \ref{fig:blurring:sub2}).

\begin{figure}
\centering
\begin{subfigure}{0.4\textwidth}
 \centering
 \includegraphics[width=0.95\textwidth]{"./image/median_blurring"}
 \caption{Blurring by taking the median of the surrounding pixels.}
 \label{fig:blurring:sub1}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
 \centering
 \includegraphics[width=0.95\textwidth]{"./image/bilateral_smoothing"}
 \caption{Bilateral smoothing; applying a weighted guassian smoothing.}
 \label{fig:blurring:sub2}
\end{subfigure}
\caption{Two blurring techniques to cut down noise}
\label{fig:blurring}
\end{figure}

The FLIR Lepton camera we're using for this project is a very low resultion camera- only 80x60 in a 50 degree field of view- so smoothing is not really needed; each pixel covers several square feet of most objects it's looking at, so the images look like theyve been through a heavy mean filtering process already (Figure \ref{fig:buoy_ex}. However, should the Sailbot upgrade to a higher resultion camera (as is being currently considered) then smoothing algorithms while play a more important role in our postprocessing. 

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{"./image/buoy_example"}
\caption{Buoy at 50 meters, no smoothing or processing}
\label{fig:buoy_ex}
\end{figure}

After reducing noise, 